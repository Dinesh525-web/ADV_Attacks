{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model  \u001b[38;5;66;03m# Import model directly\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_embeddings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from src.model_handler import model  # Import model directly\n",
    "from src.embeddings import get_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thrishala/mental_health_chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example medical consultation text\n",
    "text = \"I'm feeling very anxious and unable to sleep. What should I do?\"\n",
    "\n",
    "# Get embeddings before attack\n",
    "original_embedding = get_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial embedding (e.g., small perturbation)\n",
    "epsilon = 0.01\n",
    "adversarial_embedding = original_embedding + epsilon * torch.randn_like(original_embedding)\n",
    "\n",
    "# Compare embeddings\n",
    "diff = torch.norm(original_embedding - adversarial_embedding).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Embedding Norm: {torch.norm(original_embedding).item()}\")\n",
    "print(f\"Adversarial Embedding Norm: {torch.norm(adversarial_embedding).item()}\")\n",
    "print(f\"Difference: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings (simple)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(original_embedding[0].cpu().numpy(), label=\"Original\")\n",
    "plt.plot(adversarial_embedding[0].cpu().numpy(), label=\"Adversarial\", linestyle=\"dashed\")\n",
    "plt.legend()\n",
    "plt.title(\"Embedding Attack Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers accelerate bitsandbytes numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # ‚úÖ Hugging Face Authentication\n",
    "# hf_auth = os.getenv(\"HF_TOKEN\")  # Set before running or manually: \"your-huggingface-access-token\"\n",
    "\n",
    "# # ‚úÖ Load the Model\n",
    "# model_id = \"thrishala/mental_health_chatbot\"\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"üîπ Using device: {device}\")\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_id, token=hf_auth)\n",
    "# model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id, \n",
    "#     device_map=\"auto\", \n",
    "#     token=hf_auth\n",
    "# )\n",
    "\n",
    "# model.eval()\n",
    "# print(\"‚úÖ Model & Tokenizer Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_embedding(text):\n",
    "#     \"\"\"Extracts token embeddings from the model\"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "#     # ‚úÖ Get last hidden state embeddings\n",
    "#     embeddings = outputs.hidden_states[-1].squeeze(0)\n",
    "#     return embeddings\n",
    "\n",
    "# # ‚úÖ Test embedding extraction\n",
    "# test_text = \"I feel anxious and stressed all the time. What should I do?\"\n",
    "# embeddings = extract_embedding(test_text)\n",
    "\n",
    "# print(\"üîπ Embedding Shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# def perturb_embedding(embedding, epsilon=0.05):\n",
    "#     \"\"\"Adds small perturbations to the embeddings to mislead the model.\"\"\"\n",
    "#     noise = torch.randn_like(embedding) * epsilon\n",
    "#     perturbed_embedding = embedding + noise\n",
    "#     return perturbed_embedding\n",
    "\n",
    "# # ‚úÖ Test by perturbing extracted embeddings\n",
    "# perturbed_embeddings = perturb_embedding(embeddings)\n",
    "# print(\"‚úÖ Perturbed Embeddings Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_with_embeddings(perturbed_embedding):\n",
    "#     \"\"\"Generates response using perturbed embeddings\"\"\"\n",
    "#     # Ensure shape is correct\n",
    "#     perturbed_embedding = perturbed_embedding.unsqueeze(0).to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             inputs_embeds=perturbed_embedding,\n",
    "#             max_new_tokens=50,\n",
    "#             temperature=0.8\n",
    "#         )\n",
    "\n",
    "#     return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# # ‚úÖ Run attack\n",
    "# response = generate_with_embeddings(perturbed_embeddings)\n",
    "# print(\"‚ö†Ô∏è Adversarial Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_response = tokenizer.decode(model.generate(tokenizer(test_text, return_tensors=\"pt\").to(device))[\"sequences\"][0], skip_special_tokens=True)\n",
    "# adversarial_response = generate_with_embeddings(perturbed_embeddings)\n",
    "\n",
    "# print(\"üìù Original Response:\\n\", original_response)\n",
    "# print(\"\\n‚ö†Ô∏è Adversarial Response:\\n\", adversarial_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADV_Attacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
